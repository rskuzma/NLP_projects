{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to load elmo to local disk:\n",
    "#download the model to local so it can be used again and again\n",
    "$ mkdir module/module_elmo2\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "$ curl -L \"https://tfhub.dev/google/elmo/2?tf-hub-format=compressed\" | tar -zxvC module/module_elmo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for elmo\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm  # progress bar\n",
    "import re\n",
    "import time\n",
    "import pickle  # pickle is a file loader?\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumes only for now\n",
    "# gives df with list of strings (tokenized) as well as lemmatized list of strings\n",
    "\n",
    "ec2_resumes_path = '/home/ubuntu/NLP_projects/job_recommender_project/data/large_files/lf_cleaned_lemmatized_tokenized_resumes.csv'\n",
    "resumes = pd.read_csv(ec2_resumes_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resumes['lemmatized_resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### can use the above to turn resumes['lemmatized_resume'] into a list'\n",
    "# ##### saving and loading w/CSV makes things strings. should have pickled it instead to get list\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "# # extract ELMo embeddings from each batch\n",
    "resumes['lemmatized_resume_list'] = resumes['lemmatized_resume'].apply(literal_eval) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# resumes['lemmatized _resume'] is pandas.core.series.Series. We need a list\n",
    "resumes_sentences = resumes['lemmatized_resume'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using:https://towardsdatascience.com/transfer-learning-using-elmo-embedding-c4a7e415103c\n",
    "        \n",
    "key!! saving elmo2 locally        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"/home/ubuntu/module/module_elmo2\", trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = elmo(\n",
    "# [\"the cat is on the mat\", \"what are you doing in evening\"],\n",
    "# signature=\"default\",\n",
    "# as_dict=True)[\"elmo\"]\n",
    "# with tf.Session() as session:\n",
    "#     session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#     message_embeddings = session.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elmo = hub.Module(\"/home/ubuntu/module/module_elmo2\", trainable=False)\n",
    "# tokens_input = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"],\n",
    "# [\"what\", \"are\", \"you\", \"doing\", \"in\", \"evening\"]]\n",
    "# tokens_length = [6, 5]\n",
    "# embeddings = elmo(\n",
    "# inputs={\n",
    "# \"tokens\": tokens_input,\n",
    "# \"sequence_len\": tokens_length\n",
    "# },\n",
    "# signature=\"tokens\",\n",
    "# as_dict=True)[\"elmo\"]\n",
    "# with tf.Session() as session:\n",
    "#     session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#     message_embeddings2 = session.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_embeddings2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using in REST API or backend for multiple inputs, rather than initializing sessions for each call, which is a overhead, one efficient way can be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embed_elmo2(module):\n",
    "#     with tf.Graph().as_default():\n",
    "#         sentences = tf.placeholder(tf.string)\n",
    "#         embed = hub.Module(module)\n",
    "#         embeddings = embed(sentences)\n",
    "#         session = tf.train.MonitoredSession()\n",
    "#     return lambda x: session.run(embeddings, {sentences: x})\n",
    "\n",
    "# embed_fn = embed_elmo2('/home/ubuntu/module/module_elmo2')\n",
    "# embed_fn([\"i am sambit\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tds article has X = array of clean text; Y as array of sentiment (0 for negative, 1 for positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now going back to analytics vidhya article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MY ELMO_VECTORS FUNCTION\n",
    "\n",
    "# def elmo_vectors(x):\n",
    "#     if type(x) == np.ndarray:\n",
    "#         print('input is an np.ndarray. using \\'to list()\\'')\n",
    "#         embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]    \n",
    "#     elif type(x) == list:\n",
    "#         print('input is an list')\n",
    "#         embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "#     else:\n",
    "#         print('input is not a np.ndarray or a list')\n",
    "#         embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         sess.run(tf.tables_initializer())\n",
    "#         # return average of ELMo features\n",
    "#         return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ANALYTICS VIDYHA ELMO_VECTORS_FUNCTION\n",
    "def elmo_vectors(x, options = run_opts):\n",
    "    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### keep batches in list\n",
    "# list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "resumes_sentences_small = resumes_sentences[0:10]\n",
    "small_batches = [resumes_sentences_small[i:i+2] for i in range(0,len(resumes_sentences_small),2)]\n",
    "# batches of 2, total of 10 (out of 1200 resumes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resumes['lemmatized_resume_list'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_1_apply_default/bilm/embedding_lookup (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Mean_2/_231]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_1_apply_default/bilm/embedding_lookup (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'module_1_apply_default/bilm/embedding_lookup':\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-245aff7af5cc>\", line 2, in <module>\n    elmo_train = [elmo_vectors(resumes['lemmatized_resume']) for x in small_batches]\n  File \"<ipython-input-39-245aff7af5cc>\", line 2, in <listcomp>\n    elmo_train = [elmo_vectors(resumes['lemmatized_resume']) for x in small_batches]\n  File \"<ipython-input-36-824477516451>\", line 3, in elmo_vectors\n    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py\", line 255, in __call__\n    name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py\", line 561, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1453, in import_meta_graph\n    **kwargs)[0]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node module_1_apply_default/bilm/embedding_lookup}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Mean_2/_231]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node module_1_apply_default/bilm/embedding_lookup}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-245aff7af5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract ELMo embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0melmo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresumes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized_resume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-245aff7af5cc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract ELMo embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0melmo_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0melmo_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresumes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lemmatized_resume'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msmall_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-824477516451>\u001b[0m in \u001b[0;36melmo_vectors\u001b[0;34m(x, options)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# return average of ELMo features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_1_apply_default/bilm/embedding_lookup (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Mean_2/_231]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[1219,7259,50,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node module_1_apply_default/bilm/embedding_lookup (defined at /home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'module_1_apply_default/bilm/embedding_lookup':\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 153, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-39-245aff7af5cc>\", line 2, in <module>\n    elmo_train = [elmo_vectors(resumes['lemmatized_resume']) for x in small_batches]\n  File \"<ipython-input-39-245aff7af5cc>\", line 2, in <listcomp>\n    elmo_train = [elmo_vectors(resumes['lemmatized_resume']) for x in small_batches]\n  File \"<ipython-input-36-824477516451>\", line 3, in elmo_vectors\n    embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py\", line 255, in __call__\n    name=name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py\", line 561, in create_apply_graph\n    import_scope=relative_scope_name)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1453, in import_meta_graph\n    **kwargs)[0]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py\", line 1477, in _import_meta_graph_with_return_elements\n    **kwargs))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/meta_graph.py\", line 809, in import_scoped_meta_graph_with_return_elements\n    return_elements=return_elements)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\n    producer_op_list=producer_op_list)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\n    _ProcessNewOps(graph)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3561, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3451, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Extract ELMo embeddings\n",
    "elmo_train = [elmo_vectors(resumes['lemmatized_resume']) for x in small_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save elmo_train_new\n",
    "pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_train_new, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# save elmo_test_new\n",
    "pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_test_new, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
    "elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "elmo_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_resumes_sentences = resumes_sentences[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(small_resumes_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(small_resumes_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_resumes_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a random sentence\n",
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(x):\n",
    "  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    # return average of ELMo features\n",
    "    return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = [train[i:i+100] for i in range(0,train.shape[0],100)]\n",
    "list_test = [test[i:i+100] for i in range(0,test.shape[0],100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ELMo embeddings\n",
    "elmo_train = [elmo_vectors(x['clean_tweet']) for x in list_train]\n",
    "elmo_test = [elmo_vectors(x['clean_tweet']) for x in list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
    "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save elmo_train_new\n",
    "pickle_out = open(\"elmo_train_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_train_new, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "# save elmo_test_new\n",
    "pickle_out = open(\"elmo_test_03032019.pickle\",\"wb\")\n",
    "pickle.dump(elmo_test_new, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_train_03032019.pickle\", \"rb\")\n",
    "elmo_train_new = pickle.load(pickle_in)\n",
    "\n",
    "# load elmo_train_new\n",
    "pickle_in = open(\"elmo_test_03032019.pickle\", \"rb\")\n",
    "elmo_test_new = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_new, \n",
    "                                                  train['label'],  \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = lreg.predict(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(yvalid, preds_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on test set\n",
    "preds_test = lreg.predict(elmo_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare submission dataframe\n",
    "sub = pd.DataFrame({'id':test['id'], 'label':preds_test})\n",
    "\n",
    "# write predictions to a CSV file\n",
    "sub.to_csv(\"sub_lreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other things to try...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will try gluon for pre-trained ELMo\n",
    "https://gluon-nlp.mxnet.io/master/examples/sentence_embedding/elmo_sentence_representation.html?highlight=elmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# import numpy as np\n",
    "# import io\n",
    "\n",
    "# import mxnet as mx\n",
    "# from mxnet import gluon\n",
    "# import gluonnlp as nlp\n",
    "# nlp.utils.check_version('0.7.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
