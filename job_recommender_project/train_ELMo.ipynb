{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to load elmo to local disk:\n",
    "#download the model to local so it can be used again and again\n",
    "$ mkdir module/module_elmo2\n",
    "# Download the module, and uncompress it to the destination folder. \n",
    "$ curl -L \"https://tfhub.dev/google/elmo/2?tf-hub-format=compressed\" | tar -zxvC module/module_elmo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#NLP\n",
    "#import spacy\n",
    "import re\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# file loading\n",
    "import pickle\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a Tesla V100 with a P3, K80 with P2 \n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumes only for now\n",
    "# gives df with list of strings (tokenized) as well as lemmatized list of strings\n",
    "\n",
    "ec2_resumes_path = '/home/ubuntu/NLP_projects/job_recommender_project/data/large_files/lf_cleaned_lemmatized_tokenized_resumes.csv'\n",
    "ec2_pickle_resumes_path = '/home/ec2-user/NLP_projects/job_recommender_project/data/resumes_with_list_of_list.pickle'\n",
    "\n",
    "resumes = pd.read_pickle(ec2_pickle_resumes_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resumes['lol'][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['los'] = resumes['lol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resumes['los'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(resumes['los'])):\n",
    "    for j in range (0, len(resumes['los'][i])):\n",
    "        resumes['los'][i][j] = ' '.join(resumes['los'][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes['los'][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_in = resumes['los']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the lenghts of each resume and resume ID for reference\n",
    "\n",
    "# for x in range(len(elmo_in)):\n",
    "#     print(x, ':  ', len(elmo_in[x]))\n",
    "\n",
    "#     #elmo_in[28] has 212 sentences\n",
    "#     #\n",
    "#     #elmo_in[34] has 945 sentences\n",
    "#     #elmo_in[75] has 3 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine resume length in sentences\n",
    "\n",
    "\n",
    "lengths = []\n",
    "for i in range(0, len(elmo_in)):\n",
    "    lengths.extend([len(elmo_in[i])])\n",
    "\n",
    "#lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at distributions of resume length\n",
    "\n",
    "plt.hist(lengths, bins=range(0, 1000, 10))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lengths, bins=range(0, 200, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"example of a short resume:\")\n",
    "print(\"resume number 244\")\n",
    "print(\"resume length: {} sentences\".format(len(elmo_in[244])))\n",
    "print(elmo_in[244])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"example of a medium resume:\")\n",
    "print(\"resume number 202\")\n",
    "print(\"resume length: {} sentences\".format(len(elmo_in[202])))\n",
    "print(elmo_in[202])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"example of a long resume:\")\n",
    "print(\"resume number 28\")\n",
    "print(\"resume length: {} sentences\".format(len(elmo_in[28])))\n",
    "print(elmo_in[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min: {}'.format(np.amin(lengths)))\n",
    "print('max: {}'.format(np.amax(lengths)))\n",
    "print('median: {}'.format(np.median(lengths)))\n",
    "print('mean: {}'.format(np.mean(lengths)))\n",
    "print('stdev: {}'.format(np.std(lengths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_copy = lengths.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_in_smalls = elmo_in.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_in_smalls = elmo_in_smalls.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(elmo_in_smalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in elmo_in_smalls:\n",
    "    if len(i) > 100:\n",
    "        elmo_in_smalls.remove(i)\n",
    "    if len(i) <2:\n",
    "        elmo_in_smalls.remove(i)\n",
    "\n",
    "#elmo_in_smalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[0] ',elmo_in_smalls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[0][3] ', type(elmo_in_smalls[0][3]), len(elmo_in_smalls[0][3]), elmo_in_smalls[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(elmo_in_smalls)):\n",
    "    for j in range (0, len(elmo_in_smalls[i])):\n",
    "        if len(elmo_in_smalls[i][j])<2:\n",
    "            print(i, j, elmo_in_smalls[i][j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elmo_in_smalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_smalls = []\n",
    "for i in range(0, len(elmo_in_smalls)):\n",
    "    lengths_smalls.extend([len(elmo_in_smalls[i])])\n",
    "\n",
    "#lengths_smalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at distributions of resume length\n",
    "\n",
    "plt.hist(lengths_smalls, bins=range(0, 100, 5))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have lengths_smalls for each length\n",
    "# now we have elmo_in_smalls for each resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(elmo_in_smalls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have elmo saved locally\n",
    "elmo = hub.Module(\"/home/ec2-user/module/module_elmo2\", trainable=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elmo_in_smalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SAVING ELMO_IN_SMALLS\n",
    "type(elmo_in_smalls)\n",
    "# save elmo in smalls\n",
    "np_elmo_in_smalls = np.asarray(elmo_in_smalls)\n",
    "np.save('elmo_resumes_under_100_sentences', np_elmo_in_smalls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_try = []\n",
    "# for i in range(0, len(elmo_in_smalls[0])):\n",
    "#     first_try = elmo_vectors(elmo_in_smalls[0][i])\n",
    "#     print(first_try)\n",
    "\n",
    "\n",
    "#trying on elmo_in_smalls[0]\n",
    "embeddings = elmo(elmo_in_smalls[0], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "print(\"embeddings is type {} and shape {}\".format(type(embeddings), embeddings.shape))\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings_2d = session.run(tf.reduce_mean(embeddings,axis=0))\n",
    "    print(\"message_embeddings_2d is type {} and shape {}\".format(type(message_embeddings_2d), message_embeddings_2d.shape))\n",
    "    message_embeddings_1d = tf.reduce_mean(tf.convert_to_tensor(message_embeddings_2d), axis = 0, keepdims=True)\n",
    "    print(\"message_embeddings_1d is type {} and shape {}\".format(type(message_embeddings_1d), message_embeddings_1d.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = tf.dtypes.cast(embeddings, tf.float16)  # [1, 2], dtype=tf.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:  print(message_embeddings_1d.eval()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying on elmo_in_smalls[1]\n",
    "embeddings1 = elmo(elmo_in_smalls[1], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "print(\"embeddings is type {} and shape {}\".format(type(embeddings1), embeddings1.shape))\n",
    "with tf.Session() as session:\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    message_embeddings1_2d = session.run(tf.reduce_mean(embeddings1,axis=0))\n",
    "    print(\"message_embeddings1_2d is type {} and shape {}\".format(type(message_embeddings1_2d), message_embeddings1_2d.shape))\n",
    "    message_embeddings1_1d = session.run(tf.reduce_mean(tf.convert_to_tensor(message_embeddings1_2d), axis = 0, keepdims=True))\n",
    "    print(\"message_embeddings1_1d is type {} and shape {}\".format(type(message_embeddings1_1d), message_embeddings1_1d.shape))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message_embeddings1_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:  print(message_embeddings1_1d.eval()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess: print(cosine_similarity(message_embeddings_1d.eval(), message_embeddings1_1d.eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"embeddings shape: {}\".format(embeddings.shape))\n",
    "# print(\"elmo_in_smalls[0] sentences: {}\".format(len(elmo_in_smalls[0])))\n",
    "# max_sentence_length = 0\n",
    "# for i in range(0, len(elmo_in_smalls[0])):\n",
    "#     if len(elmo_in_smalls[0][i].split()) > max_sentence_length:\n",
    "#         max_sentence_length = len(elmo_in_smalls[0][i])\n",
    "                                  \n",
    "# print(\"elmo_in_smalls[0] max sentence length: {}\".format(max_sentence_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elmo_in_smalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(elmo_in_smalls[129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### try this right after imports to load elmo_in_smalls\n",
    "elmo_in_smalls = np.load('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences.npy', allow_pickle=True).tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many attempts\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#NLP\n",
    "#import spacy\n",
    "import re\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# file loading\n",
    "import pickle\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from time import process_time\n",
    "\n",
    "### try this right after imports to load elmo_in_smalls\n",
    "elmo_in_smalls = np.load('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences.npy', allow_pickle=True).tolist()\n",
    "\n",
    "\n",
    "## this was the instantiation of elmo\n",
    "elmo = hub.Module(\"/home/ec2-user/module/module_elmo2\", trainable=False)\n",
    "\n",
    "# for all embeddings\n",
    "#resume_embeddings_append_regular = []\n",
    "resume_embeddings_append_transpose = []\n",
    "#resume_embeddings_extend_regular = []\n",
    "#resume_embeddings_extend_transpose = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, len(elmo_in_smalls))):\n",
    "    t1 = process_time()\n",
    "    # save np array of embeddings\n",
    "    if i % 50 == 0:\n",
    "        works_ELMo_embeddings_resumes = np.asarray(resume_embeddings_append_transpose)\n",
    "        np.save('ELMo_embeddings_resumes_0to_{}'.format(i), works_ELMo_embeddings_resumes) \n",
    "    \n",
    "    #print('elmo_in_smalls[{}]'.format(i))\n",
    "    embeddings_3d = elmo(elmo_in_smalls[i], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "    #print('3d size: {}'.format(embeddings_3d.shape))\n",
    "    #print('3d type ', type(embeddings_3d))\n",
    "    t2 = process_time()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings_2d = session.run(tf.reduce_mean(embeddings_3d,axis=0))\n",
    "        #print('2d size: {}'.format(embeddings_2d.shape))\n",
    "        #print('2d type ', type(embeddings_2d))\n",
    "        t3 = process_time()\n",
    "        \n",
    "        \n",
    "        embeddings_1d = session.run(tf.reduce_mean(tf.convert_to_tensor(embeddings_2d), axis = 0, keepdims=True))\n",
    "        #print('1d size: {}'.format(embeddings_1d.shape))\n",
    "        #print('1d type ', type(embeddings_1d))\n",
    "        t4 = process_time()\n",
    "        \n",
    "        transpose = embeddings_1d.T\n",
    "        #print(transpose.shape)\n",
    "        #print('transpose type: ', type(transpose))\n",
    "        t5 = process_time()\n",
    "        \n",
    "        resume_embeddings_append_regular.append(embeddings_1d)\n",
    "        t6 = process_time()\n",
    "        \n",
    "        resume_embeddings_append_transpose.append(transpose)\n",
    "        t7 = process_time()\n",
    "        \n",
    "        resume_embeddings_extend_regular.extend(embeddings_1d)\n",
    "        t8 = process_time()\n",
    "        \n",
    "        resume_embeddings_extend_transpose.extend(transpose)\n",
    "        t9 = process_time()\n",
    "        \n",
    "        #print('length of resume_embeddings_append_regular: {}'.format(len(resume_embeddings_append_regular)))\n",
    "        #print('length of resume_embeddings_append_transpose: {}'.format(len(resume_embeddings_append_transpose)))\n",
    "        #print('length of resume_embeddings_extend_regular: {}'.format(len(resume_embeddings_extend_regular)))\n",
    "        #print('length of resume_embeddings_extend_transpose: {}'.format(len(resume_embeddings_extend_transpose)))      \n",
    "        \n",
    "        #print('shape of resume_embeddings_append_regular[{}]: {}'.format(i, resume_embeddings_append_regular[i].shape))\n",
    "        #print('shape of resume_embeddings_append_transpose[{}]: {}'.format(i, resume_embeddings_append_transpose[i].shape))                                                                        \n",
    "        #print('shape of resume_embeddings_extend_regular[{}]: {}'.format(i, resume_embeddings_extend_regular[i].shape))                                                                        \n",
    "        #print('shape of resume_embeddings_extend_transpose[{}]: {}'.format(i, resume_embeddings_extend_transpose[i].shape))                                                                        \n",
    "               \n",
    "    \n",
    "    \n",
    "#         print('Run {}'.format(i))\n",
    "#         print('all times from start of run {}'.format(i))\n",
    "#         print('3d embedding time: {}'.format(t2 - t1))\n",
    "#         print('2d embedding time: {}'.format(t3 - t2))\n",
    "#         print('1d embedding time: {}'.format(t4 - t3))\n",
    "#         print('time to transpose (t5-t4): {}'.format(t5 - t4))\n",
    "#         print('append_regular time (t6-t5): {}'.format(t6-t5))\n",
    "#         print('append_transpose time (t7-t6): {}'.format(t7-t6))\n",
    "#         print('extend_regular time (t8-t7): {}'.format(t8-t7))\n",
    "#         print('extend_transpose time (t9-t8): {}'.format(t9-t8))\n",
    "#         print('Total time run {}: {}'.format(i, t9-t1))         \n",
    "#         print('\\n\\n\\n\\t\\t\\tEND OF RUN')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARNING:tensorflow:From train_elmo.py:31: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
    "\n",
    "WARNING:tensorflow:From train_elmo.py:46: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
    "\n",
    "2020-04-23 16:40:21.396830: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2020-04-23 16:40:21.417314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300070000 Hz\n",
    "2020-04-23 16:40:21.417704: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b1b840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
    "2020-04-23 16:40:21.417730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
    "WARNING:tensorflow:From train_elmo.py:51: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
    "\n",
    "WARNING:tensorflow:From train_elmo.py:51: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "======================================================\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving tf.sess out of for loop\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# elmo_in_smalls = np.load('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences.npy', allow_pickle=True).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences', np.asarray(elmo_in_smalls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35\n",
      "1 9\n",
      "2 65\n",
      "3 63\n",
      "4 46\n",
      "5 35\n",
      "6 56\n",
      "7 76\n",
      "8 50\n",
      "9 4\n",
      "10 15\n",
      "11 32\n",
      "12 60\n",
      "13 33\n",
      "14 87\n",
      "15 65\n",
      "16 26\n",
      "17 7\n",
      "18 31\n",
      "19 28\n",
      "20 31\n",
      "21 14\n",
      "22 36\n",
      "23 4\n",
      "24 24\n",
      "25 72\n",
      "26 15\n",
      "27 15\n",
      "28 31\n",
      "29 69\n",
      "30 50\n",
      "31 41\n",
      "32 29\n",
      "33 50\n",
      "34 6\n",
      "35 22\n",
      "36 15\n",
      "37 12\n",
      "38 64\n",
      "39 11\n",
      "40 22\n",
      "41 6\n",
      "42 12\n",
      "43 25\n",
      "44 6\n",
      "45 40\n",
      "46 8\n",
      "47 61\n",
      "48 10\n",
      "49 17\n",
      "50 17\n",
      "51 14\n",
      "52 32\n",
      "53 11\n",
      "54 17\n",
      "55 9\n",
      "56 26\n",
      "57 57\n",
      "58 20\n",
      "59 32\n",
      "60 3\n",
      "61 15\n",
      "62 3\n",
      "63 21\n",
      "64 28\n",
      "65 23\n",
      "66 70\n",
      "67 31\n",
      "68 30\n",
      "69 17\n",
      "70 92\n",
      "71 9\n",
      "72 3\n",
      "73 74\n",
      "74 32\n",
      "75 2\n",
      "76 68\n",
      "77 3\n",
      "78 30\n",
      "79 23\n",
      "80 26\n",
      "81 3\n",
      "82 18\n",
      "83 40\n",
      "84 35\n",
      "85 61\n",
      "86 2\n",
      "87 20\n",
      "88 93\n",
      "89 26\n",
      "90 42\n",
      "91 47\n",
      "92 42\n",
      "93 24\n",
      "94 100\n",
      "95 42\n",
      "96 45\n",
      "97 25\n",
      "98 12\n",
      "99 26\n",
      "100 88\n",
      "101 5\n",
      "102 30\n",
      "103 46\n",
      "104 60\n",
      "105 57\n",
      "106 36\n",
      "107 7\n",
      "108 58\n",
      "109 35\n",
      "110 27\n",
      "111 35\n",
      "112 16\n",
      "113 58\n",
      "114 37\n",
      "115 32\n",
      "116 19\n",
      "117 26\n",
      "118 4\n",
      "119 33\n",
      "120 2\n",
      "121 11\n",
      "122 74\n",
      "123 26\n",
      "124 51\n",
      "125 4\n",
      "126 41\n",
      "127 19\n",
      "128 66\n",
      "129 3\n",
      "130 40\n",
      "131 68\n",
      "132 17\n",
      "133 55\n",
      "134 35\n",
      "135 54\n",
      "136 20\n",
      "137 27\n",
      "138 3\n",
      "139 8\n",
      "140 59\n",
      "141 16\n",
      "142 35\n",
      "143 36\n",
      "144 27\n",
      "145 35\n",
      "146 30\n",
      "147 7\n",
      "148 47\n",
      "149 12\n",
      "150 12\n",
      "151 2\n",
      "152 40\n",
      "153 45\n",
      "154 30\n",
      "155 55\n",
      "156 25\n",
      "157 3\n",
      "158 64\n",
      "159 71\n",
      "160 4\n",
      "161 52\n",
      "162 29\n",
      "163 7\n",
      "164 21\n",
      "165 6\n",
      "166 24\n",
      "167 29\n",
      "168 15\n",
      "169 9\n",
      "170 26\n",
      "171 34\n",
      "172 85\n",
      "173 28\n",
      "174 42\n",
      "175 22\n",
      "176 9\n",
      "177 10\n",
      "178 47\n",
      "179 4\n",
      "180 31\n",
      "181 20\n",
      "182 19\n",
      "183 11\n",
      "184 23\n",
      "185 28\n",
      "186 24\n",
      "187 25\n",
      "188 60\n",
      "189 78\n",
      "190 22\n",
      "191 45\n",
      "192 17\n",
      "193 25\n",
      "194 47\n",
      "195 4\n",
      "196 2\n",
      "197 21\n",
      "198 36\n",
      "199 12\n",
      "200 51\n",
      "201 93\n",
      "202 40\n",
      "203 9\n",
      "204 35\n",
      "205 55\n",
      "206 86\n",
      "207 55\n",
      "208 31\n",
      "209 4\n",
      "210 41\n",
      "211 24\n",
      "212 36\n",
      "213 48\n",
      "214 39\n",
      "215 19\n",
      "216 18\n",
      "217 4\n",
      "218 30\n",
      "219 5\n",
      "220 16\n",
      "221 16\n",
      "222 16\n",
      "223 19\n",
      "224 23\n",
      "225 17\n",
      "226 7\n",
      "227 9\n",
      "228 27\n",
      "229 10\n",
      "230 3\n",
      "231 4\n",
      "232 44\n",
      "233 25\n",
      "234 66\n",
      "235 37\n",
      "236 5\n",
      "237 6\n",
      "238 19\n",
      "239 45\n",
      "240 18\n",
      "241 10\n",
      "242 23\n",
      "243 41\n",
      "244 16\n",
      "245 19\n",
      "246 14\n",
      "247 25\n",
      "248 7\n",
      "249 20\n",
      "250 23\n",
      "251 3\n",
      "252 29\n",
      "253 76\n",
      "254 21\n",
      "255 5\n",
      "256 16\n",
      "257 39\n",
      "258 4\n",
      "259 9\n",
      "260 4\n",
      "261 13\n",
      "262 90\n",
      "263 53\n",
      "264 4\n",
      "265 47\n",
      "266 23\n",
      "267 11\n",
      "268 18\n",
      "269 19\n",
      "270 4\n",
      "271 2\n",
      "272 40\n",
      "273 40\n",
      "274 3\n",
      "275 24\n",
      "276 19\n",
      "277 71\n",
      "278 18\n",
      "279 4\n",
      "280 17\n",
      "281 7\n",
      "282 18\n",
      "283 22\n",
      "284 4\n",
      "285 35\n",
      "286 5\n",
      "287 3\n",
      "288 3\n",
      "289 54\n",
      "290 16\n",
      "291 16\n",
      "292 59\n",
      "293 6\n",
      "294 3\n",
      "295 6\n",
      "296 3\n",
      "297 3\n",
      "298 31\n",
      "299 13\n",
      "300 53\n",
      "301 4\n",
      "302 9\n",
      "303 18\n",
      "304 23\n",
      "305 2\n",
      "306 16\n",
      "307 14\n",
      "308 4\n",
      "309 3\n",
      "310 37\n",
      "311 6\n",
      "312 41\n",
      "313 7\n",
      "314 19\n",
      "315 4\n",
      "316 4\n",
      "317 17\n",
      "318 78\n",
      "319 4\n",
      "320 57\n",
      "321 33\n",
      "322 8\n",
      "323 33\n",
      "324 33\n",
      "325 18\n",
      "326 7\n",
      "327 8\n",
      "328 8\n",
      "329 33\n",
      "330 5\n",
      "331 38\n",
      "332 18\n",
      "333 66\n",
      "334 66\n",
      "335 75\n",
      "336 27\n",
      "337 16\n",
      "338 27\n",
      "339 44\n",
      "340 12\n",
      "341 43\n",
      "342 22\n",
      "343 6\n",
      "344 51\n",
      "345 62\n",
      "346 66\n",
      "347 2\n",
      "348 57\n",
      "349 7\n",
      "350 88\n",
      "351 62\n",
      "352 42\n",
      "353 4\n",
      "354 41\n",
      "355 36\n",
      "356 66\n",
      "357 33\n",
      "358 19\n",
      "359 26\n",
      "360 57\n",
      "361 56\n",
      "362 3\n",
      "363 14\n",
      "364 26\n",
      "365 8\n",
      "366 8\n",
      "367 18\n",
      "368 61\n",
      "369 24\n",
      "370 14\n",
      "371 29\n",
      "372 96\n",
      "373 28\n",
      "374 37\n",
      "375 12\n",
      "376 11\n",
      "377 15\n",
      "378 5\n",
      "379 32\n",
      "380 17\n",
      "381 5\n",
      "382 30\n",
      "383 12\n",
      "384 5\n",
      "385 4\n",
      "386 26\n",
      "387 30\n",
      "388 24\n",
      "389 26\n",
      "390 10\n",
      "391 63\n",
      "392 9\n",
      "393 44\n",
      "394 17\n",
      "395 19\n",
      "396 5\n",
      "397 17\n",
      "398 2\n",
      "399 3\n",
      "400 30\n",
      "401 9\n",
      "402 9\n",
      "403 11\n",
      "404 6\n",
      "405 40\n",
      "406 5\n",
      "407 3\n",
      "408 28\n",
      "409 45\n",
      "410 16\n",
      "411 11\n",
      "412 60\n",
      "413 9\n",
      "414 14\n",
      "415 3\n",
      "416 20\n",
      "417 86\n",
      "418 3\n",
      "419 7\n",
      "420 20\n",
      "421 29\n",
      "422 14\n",
      "423 28\n",
      "424 25\n",
      "425 12\n",
      "426 85\n",
      "427 21\n",
      "428 31\n",
      "429 3\n",
      "430 31\n",
      "431 30\n",
      "432 3\n",
      "433 52\n",
      "434 16\n",
      "435 23\n",
      "436 19\n",
      "437 2\n",
      "438 3\n",
      "439 49\n",
      "440 50\n",
      "441 18\n",
      "442 22\n",
      "443 79\n",
      "444 30\n",
      "445 12\n",
      "446 33\n",
      "447 10\n",
      "448 43\n",
      "449 31\n",
      "450 20\n",
      "451 6\n",
      "452 19\n",
      "453 51\n",
      "454 32\n",
      "455 2\n",
      "456 4\n",
      "457 2\n",
      "458 2\n",
      "459 44\n",
      "460 10\n",
      "461 17\n",
      "462 34\n",
      "463 5\n",
      "464 5\n",
      "465 5\n",
      "466 29\n",
      "467 10\n",
      "468 4\n",
      "469 59\n",
      "470 28\n",
      "471 11\n",
      "472 7\n",
      "473 14\n",
      "474 14\n",
      "475 4\n",
      "476 41\n",
      "477 32\n",
      "478 28\n",
      "479 2\n",
      "480 13\n",
      "481 2\n",
      "482 6\n",
      "483 23\n",
      "484 12\n",
      "485 5\n",
      "486 22\n",
      "487 28\n",
      "488 10\n",
      "489 31\n",
      "490 25\n",
      "491 25\n",
      "492 22\n",
      "493 10\n",
      "494 29\n",
      "495 3\n",
      "496 8\n",
      "497 27\n",
      "498 2\n",
      "499 40\n",
      "500 17\n",
      "501 10\n",
      "502 9\n",
      "503 8\n",
      "504 5\n",
      "505 40\n",
      "506 27\n",
      "507 23\n",
      "508 4\n",
      "509 27\n",
      "510 8\n",
      "511 7\n",
      "512 24\n",
      "513 9\n",
      "514 7\n",
      "515 3\n",
      "516 9\n",
      "517 12\n",
      "518 17\n",
      "519 8\n",
      "520 17\n",
      "521 10\n",
      "522 20\n",
      "523 20\n",
      "524 28\n",
      "525 7\n",
      "526 47\n",
      "527 34\n",
      "528 6\n",
      "529 24\n",
      "530 16\n",
      "531 2\n",
      "532 22\n",
      "533 3\n",
      "534 5\n",
      "535 8\n",
      "536 3\n",
      "537 6\n",
      "538 40\n",
      "539 8\n",
      "540 4\n",
      "541 23\n",
      "542 38\n",
      "543 9\n",
      "544 9\n",
      "545 21\n",
      "546 49\n",
      "547 21\n",
      "548 46\n",
      "549 18\n",
      "550 14\n",
      "551 50\n",
      "552 4\n",
      "553 52\n",
      "554 48\n",
      "555 8\n",
      "556 12\n",
      "557 32\n",
      "558 4\n",
      "559 22\n",
      "560 2\n",
      "561 48\n",
      "562 9\n",
      "563 23\n",
      "564 2\n",
      "565 23\n",
      "566 82\n",
      "567 37\n",
      "568 5\n",
      "569 8\n",
      "570 26\n",
      "571 6\n",
      "572 21\n",
      "573 2\n",
      "574 29\n",
      "575 13\n",
      "576 7\n",
      "577 23\n",
      "578 35\n",
      "579 35\n",
      "580 73\n",
      "581 22\n",
      "582 4\n",
      "583 18\n",
      "584 62\n",
      "585 54\n",
      "586 22\n",
      "587 14\n",
      "588 13\n",
      "589 29\n",
      "590 54\n",
      "591 97\n",
      "592 94\n",
      "593 34\n",
      "594 12\n",
      "595 24\n",
      "596 11\n",
      "597 4\n",
      "598 7\n",
      "599 15\n",
      "600 100\n",
      "601 42\n",
      "602 4\n",
      "603 25\n",
      "604 21\n",
      "605 32\n",
      "606 52\n",
      "607 25\n",
      "608 64\n",
      "609 8\n",
      "610 2\n",
      "611 20\n",
      "612 7\n",
      "613 48\n",
      "614 2\n",
      "615 32\n",
      "616 29\n",
      "617 26\n",
      "618 84\n",
      "619 9\n",
      "620 6\n",
      "621 34\n",
      "622 6\n",
      "623 9\n",
      "624 2\n",
      "625 10\n",
      "626 47\n",
      "627 6\n",
      "628 41\n",
      "629 85\n",
      "630 33\n",
      "631 3\n",
      "632 12\n",
      "633 31\n",
      "634 10\n",
      "635 6\n",
      "636 11\n",
      "637 20\n",
      "638 12\n",
      "639 5\n",
      "640 49\n",
      "641 25\n",
      "642 25\n",
      "643 4\n",
      "644 9\n",
      "645 88\n",
      "646 56\n",
      "647 22\n",
      "648 24\n",
      "649 23\n",
      "650 8\n",
      "651 6\n",
      "652 17\n",
      "653 7\n",
      "654 42\n",
      "655 10\n",
      "656 19\n",
      "657 5\n",
      "658 6\n",
      "659 13\n",
      "660 12\n",
      "661 26\n",
      "662 12\n",
      "663 2\n",
      "664 10\n",
      "665 14\n",
      "666 13\n",
      "667 10\n",
      "668 17\n",
      "669 9\n",
      "670 6\n",
      "671 28\n",
      "672 9\n",
      "673 3\n",
      "674 61\n",
      "675 48\n",
      "676 25\n",
      "677 8\n",
      "678 3\n",
      "679 42\n",
      "680 23\n",
      "681 28\n",
      "682 17\n",
      "683 2\n",
      "684 11\n",
      "685 28\n",
      "686 64\n",
      "687 6\n",
      "688 31\n",
      "689 13\n",
      "690 25\n",
      "691 27\n",
      "692 66\n",
      "693 45\n",
      "694 21\n",
      "695 18\n",
      "696 15\n",
      "697 15\n",
      "698 22\n",
      "699 57\n",
      "700 33\n",
      "701 18\n",
      "702 20\n",
      "703 5\n",
      "704 13\n",
      "705 54\n",
      "706 29\n",
      "707 16\n",
      "708 56\n",
      "709 2\n",
      "710 14\n",
      "711 21\n",
      "712 14\n",
      "713 32\n",
      "714 16\n",
      "715 21\n",
      "716 18\n",
      "717 9\n",
      "718 27\n",
      "719 51\n",
      "720 20\n",
      "721 22\n",
      "722 22\n",
      "723 3\n",
      "724 45\n",
      "725 11\n",
      "726 57\n",
      "727 16\n",
      "728 12\n",
      "729 19\n",
      "730 16\n",
      "731 16\n",
      "732 21\n",
      "733 4\n",
      "734 35\n",
      "735 8\n",
      "736 35\n",
      "737 32\n",
      "738 6\n",
      "739 25\n",
      "740 47\n",
      "741 45\n",
      "742 57\n",
      "743 40\n",
      "744 14\n",
      "745 7\n",
      "746 21\n",
      "747 15\n",
      "748 9\n",
      "749 21\n",
      "750 49\n",
      "751 6\n",
      "752 51\n",
      "753 2\n",
      "754 14\n",
      "755 10\n",
      "756 32\n",
      "757 57\n",
      "758 20\n",
      "759 12\n",
      "760 32\n",
      "761 3\n",
      "762 12\n",
      "763 74\n",
      "764 4\n",
      "765 13\n",
      "766 40\n",
      "767 16\n",
      "768 3\n",
      "769 85\n",
      "770 5\n",
      "771 19\n",
      "772 15\n",
      "773 30\n",
      "774 5\n",
      "775 16\n",
      "776 43\n",
      "777 16\n",
      "778 85\n",
      "779 60\n",
      "780 55\n",
      "781 19\n",
      "782 28\n",
      "783 24\n",
      "784 32\n",
      "785 2\n",
      "786 100\n",
      "787 3\n",
      "788 5\n",
      "789 63\n",
      "790 18\n",
      "791 5\n",
      "792 92\n",
      "793 8\n",
      "794 19\n",
      "795 24\n",
      "796 10\n",
      "797 10\n",
      "798 27\n",
      "799 15\n",
      "800 26\n",
      "801 12\n",
      "802 23\n",
      "803 63\n",
      "804 31\n",
      "805 12\n",
      "806 20\n",
      "807 7\n",
      "808 14\n",
      "809 16\n",
      "810 8\n",
      "811 18\n",
      "812 25\n",
      "813 22\n",
      "814 38\n",
      "815 45\n",
      "816 10\n",
      "817 31\n",
      "818 45\n",
      "819 24\n",
      "820 22\n",
      "821 27\n",
      "822 13\n",
      "823 16\n",
      "824 71\n",
      "825 17\n",
      "826 28\n",
      "827 55\n",
      "828 51\n",
      "829 16\n",
      "830 2\n",
      "831 14\n",
      "832 11\n",
      "833 4\n",
      "834 87\n",
      "835 12\n",
      "836 14\n",
      "837 17\n",
      "838 10\n",
      "839 2\n",
      "840 23\n",
      "841 2\n",
      "842 61\n",
      "843 3\n",
      "844 9\n",
      "845 12\n",
      "846 63\n",
      "847 41\n",
      "848 74\n",
      "849 17\n",
      "850 74\n",
      "851 22\n",
      "852 23\n",
      "853 74\n",
      "854 31\n",
      "855 11\n",
      "856 30\n",
      "857 14\n",
      "858 20\n",
      "859 25\n",
      "860 9\n",
      "861 11\n",
      "862 16\n",
      "863 15\n",
      "864 14\n",
      "865 3\n",
      "866 16\n",
      "867 15\n",
      "868 28\n",
      "869 23\n",
      "870 66\n",
      "871 2\n",
      "872 7\n",
      "873 12\n",
      "874 3\n",
      "875 77\n",
      "876 20\n",
      "877 30\n",
      "878 8\n",
      "879 17\n",
      "880 15\n",
      "881 25\n",
      "882 17\n",
      "883 10\n",
      "884 26\n",
      "885 10\n",
      "886 8\n",
      "887 42\n",
      "888 31\n",
      "889 23\n",
      "890 57\n",
      "891 15\n",
      "892 45\n",
      "893 20\n",
      "894 4\n",
      "895 36\n",
      "896 40\n",
      "897 31\n",
      "898 31\n",
      "899 15\n",
      "900 2\n",
      "901 36\n",
      "902 27\n",
      "903 5\n",
      "904 6\n",
      "905 30\n",
      "906 31\n",
      "907 11\n",
      "908 7\n",
      "909 17\n",
      "910 37\n",
      "911 59\n",
      "912 32\n",
      "913 38\n",
      "914 25\n",
      "915 53\n",
      "916 4\n",
      "917 9\n",
      "918 4\n",
      "919 28\n",
      "920 49\n",
      "921 2\n",
      "922 19\n",
      "923 4\n",
      "924 16\n",
      "925 93\n",
      "926 7\n",
      "927 29\n",
      "928 30\n",
      "929 7\n",
      "930 15\n",
      "931 33\n",
      "932 89\n",
      "933 66\n",
      "934 4\n",
      "935 25\n",
      "936 2\n",
      "937 40\n",
      "938 21\n",
      "939 75\n",
      "940 8\n",
      "941 45\n",
      "942 39\n",
      "943 16\n",
      "944 29\n",
      "945 63\n",
      "946 79\n",
      "947 64\n",
      "948 29\n",
      "949 93\n",
      "950 4\n",
      "951 35\n",
      "952 21\n",
      "953 64\n",
      "954 7\n",
      "955 6\n",
      "956 19\n",
      "957 6\n",
      "958 2\n",
      "959 35\n",
      "960 17\n",
      "961 19\n",
      "962 23\n",
      "963 5\n",
      "964 2\n",
      "965 7\n",
      "966 2\n",
      "967 19\n",
      "968 3\n",
      "969 3\n",
      "970 3\n",
      "971 3\n",
      "972 2\n",
      "973 22\n",
      "974 2\n",
      "975 13\n",
      "976 14\n",
      "977 34\n",
      "978 2\n",
      "979 3\n",
      "980 11\n",
      "981 8\n",
      "982 16\n",
      "983 9\n",
      "984 61\n",
      "985 2\n",
      "986 10\n",
      "987 2\n",
      "988 11\n",
      "989 31\n",
      "990 2\n",
      "991 3\n",
      "992 14\n",
      "993 3\n",
      "994 2\n",
      "995 3\n",
      "996 32\n",
      "997 3\n",
      "998 2\n",
      "999 3\n",
      "1000 4\n",
      "1001 12\n",
      "1002 16\n",
      "1003 35\n",
      "1004 16\n",
      "1005 10\n",
      "1006 61\n",
      "1007 43\n",
      "1008 34\n",
      "1009 34\n",
      "1010 12\n",
      "1011 11\n",
      "1012 8\n",
      "1013 3\n",
      "1014 13\n",
      "1015 5\n",
      "1016 13\n",
      "1017 3\n",
      "1018 4\n",
      "1019 8\n",
      "1020 5\n",
      "1021 10\n",
      "1022 11\n",
      "1023 10\n",
      "1024 15\n",
      "1025 7\n",
      "1026 51\n",
      "1027 29\n",
      "1028 2\n",
      "1029 2\n",
      "1030 3\n",
      "1031 39\n",
      "1032 10\n",
      "1033 8\n",
      "1034 8\n",
      "1035 2\n",
      "1036 6\n",
      "1037 23\n",
      "1038 29\n",
      "1039 21\n",
      "1040 24\n",
      "1041 19\n",
      "1042 76\n",
      "1043 12\n",
      "1044 11\n",
      "1045 49\n",
      "1046 8\n",
      "1047 87\n",
      "1048 6\n",
      "1049 15\n",
      "1050 8\n",
      "1051 10\n",
      "1052 14\n",
      "1053 16\n",
      "1054 7\n",
      "1055 34\n",
      "1056 13\n",
      "1057 12\n",
      "1058 13\n",
      "1059 11\n",
      "1060 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(elmo_in_smalls)):\n",
    "    print(i, len(elmo_in_smalls[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#NLP\n",
    "#import spacy\n",
    "import re\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# file loading\n",
    "import pickle\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from time import process_time\n",
    "import resource\n",
    "\n",
    "### try this right after imports to load elmo_in_smalls\n",
    "elmo_in_smalls = np.load('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences.npy', allow_pickle=True).tolist()\n",
    "\n",
    "\n",
    "##################reset default graph tf###################\n",
    "tf.reset_default_graph()\n",
    "############################################\n",
    "\n",
    "## this was the instantiation of elmo\n",
    "elmo = hub.Module(\"/home/ec2-user/module/module_elmo2\", trainable=False)\n",
    "\n",
    "# for all embeddings\n",
    "resume_embeddings_append_regular = []\n",
    "resume_embeddings_append_transpose = []\n",
    "resume_embeddings_extend_regular = []\n",
    "resume_embeddings_extend_transpose = []\n",
    "\n",
    "\n",
    "print('\\n\\nstarting session\\n\\n')\n",
    "t0 = process_time()\n",
    "with tf.Session() as session:\n",
    "    t00 = process_time()\n",
    "    print('\\nstarting tf.Session took: {}'.format(t00-t0))\n",
    "    \n",
    "    t_pre_initialize_vars = process_time()\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    t_post_initialize_vars = process_time()\n",
    "    print('Time to initialize variables: {}'.format(t_post_initialize_vars-t_pre_initialize_vars))\n",
    "\n",
    "    \n",
    "    \n",
    "    print('\\n\\nstarting for loop\\n\\n')\n",
    "    for i in tqdm(range(0, 49)):#len(elmo_in_smalls))):\n",
    "        t1 = process_time()\n",
    "        # save np array of embeddings\n",
    "        if i % 50 == 0:\n",
    "            np_ELMo_embeddings_resumes = np.asarray(resume_embeddings_append_transpose)\n",
    "            np.save('new_ELMo_embeddings_resumes_0_to_{}'.format(i), np_ELMo_embeddings_resumes) \n",
    "\n",
    "        print('elmo_in_smalls[{}]'.format(i))\n",
    "        embeddings_3d = elmo(elmo_in_smalls[i], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "        embeddings_3d_f16 = tf.dtypes.cast(embeddings_3d, tf.float16)\n",
    "        print('3d size: {}'.format(embeddings_3d_f16.shape))\n",
    "        print('3d type ', type(embeddings_3d_f16))\n",
    "        t2 = process_time()\n",
    "\n",
    "        \n",
    "        embeddings_2d = session.run(tf.reduce_mean(embeddings_3d_f16,axis=0))\n",
    "        print('2d size: {}'.format(embeddings_2d.shape))\n",
    "        print('2d type ', type(embeddings_2d))\n",
    "        t3 = process_time()\n",
    "\n",
    "\n",
    "        embeddings_1d = session.run(tf.reduce_mean(tf.convert_to_tensor(embeddings_2d), axis = 0, keepdims=True))\n",
    "        print('1d size: {}'.format(embeddings_1d.shape))\n",
    "        print('1d type ', type(embeddings_1d))\n",
    "        t4 = process_time()\n",
    "\n",
    "        transpose = embeddings_1d.T\n",
    "        print(transpose.shape)\n",
    "        print('transpose type: ', type(transpose))\n",
    "        t5 = process_time()\n",
    "\n",
    "        resume_embeddings_append_regular.append(embeddings_1d)\n",
    "        t6 = process_time()\n",
    "\n",
    "        resume_embeddings_append_transpose.append(transpose)\n",
    "        t7 = process_time()\n",
    "\n",
    "        resume_embeddings_extend_regular.extend(embeddings_1d)\n",
    "        t8 = process_time()\n",
    "\n",
    "        resume_embeddings_extend_transpose.extend(transpose)\n",
    "        t9 = process_time()\n",
    "\n",
    "        print('length of resume_embeddings_append_regular: {}'.format(len(resume_embeddings_append_regular)))\n",
    "        print('length of resume_embeddings_append_transpose: {}'.format(len(resume_embeddings_append_transpose)))\n",
    "        print('length of resume_embeddings_extend_regular: {}'.format(len(resume_embeddings_extend_regular)))\n",
    "        print('length of resume_embeddings_extend_transpose: {}'.format(len(resume_embeddings_extend_transpose)))      \n",
    "\n",
    "        print('shape of resume_embeddings_append_regular[{}]: {}'.format(i, resume_embeddings_append_regular[i].shape))\n",
    "        print('shape of resume_embeddings_append_transpose[{}]: {}'.format(i, resume_embeddings_append_transpose[i].shape))                                                                        \n",
    "        print('shape of resume_embeddings_extend_regular[{}]: {}'.format(i, resume_embeddings_extend_regular[i].shape))                                                                        \n",
    "        print('shape of resume_embeddings_extend_transpose[{}]: {}'.format(i, resume_embeddings_extend_transpose[i].shape))                                                                        \n",
    "\n",
    "        #not .extend?\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nRun {}'.format(i))\n",
    "        \n",
    "        print('Iteration ', i, ' maxrss: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "        print('graph size: {}'.format(tf.graph.shape))\n",
    "        print('\\nall times from start of run {}\\n'.format(i))\n",
    "        print('3d embedding time: {}'.format(t2 - t1))\n",
    "        print('2d embedding time: {}'.format(t3 - t2))\n",
    "        print('1d embedding time: {}'.format(t4 - t3))\n",
    "        print('time to transpose (t5-t4): {}'.format(t5 - t4))\n",
    "        print('append_regular time (t6-t5): {}'.format(t6-t5))\n",
    "        print('append_transpose time (t7-t6): {}'.format(t7-t6))\n",
    "        print('extend_regular time (t8-t7): {}'.format(t8-t7))\n",
    "        print('extend_transpose time (t9-t8): {}'.format(t9-t8))\n",
    "        print('Total time run {}: {}'.format(i, t9-t1))         \n",
    "        print('\\n\\n\\n\\t\\t\\tEND OF RUN')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding graph problem?? *******TRY ME********\n",
    "=====================\n",
    "\n",
    "\n",
    "- maybe the answer is to elmo_3d every resume...then do something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-66dcda1de9dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m## this was the instantiation of elmo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/ec2-user/module/module_elmo2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# for all embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, trainable, name, tags)\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m           tags=self._tags)\n\u001b[0m\u001b[1;32m    177\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_hub/native_module.py\u001b[0m in \u001b[0;36m_create_impl\u001b[0;34m(self, name, trainable, tags)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_variables_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_saver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_hub/native_module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spec, meta_graph, trainable, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;31m# TPU training code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mscope_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_hub/native_module.py\u001b[0m in \u001b[0;36m_init_state\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mvariable_tensor_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_state_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m     self._variable_map = recover_partitioned_variable_map(\n\u001b[1;32m    450\u001b[0m         get_node_map_from_tensor_map(variable_tensor_map))\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_hub/native_module.py\u001b[0m in \u001b[0;36m_create_state_graph\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mmeta_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         import_scope=relative_scope_name)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;31m# Build a list from the variable name in the module definition to the actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[1;32m   1451\u001b[0m   return _import_meta_graph_with_return_elements(meta_graph_or_file,\n\u001b[1;32m   1452\u001b[0m                                                  \u001b[0mclear_devices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                                  **kwargs)[0]\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[0;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m           \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m           \u001b[0mreturn_elements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_elements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m           **kwargs))\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m   saver = _create_saver_from_imported_meta_graph(meta_graph_def, import_scope,\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/framework/meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph_with_return_elements\u001b[0;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements)\u001b[0m\n\u001b[1;32m    878\u001b[0m             graph.add_to_collection(\n\u001b[1;32m    879\u001b[0m                 key, from_proto(\n\u001b[0;32m--> 880\u001b[0;31m                     proto, import_scope=scope_to_prepend_to_names))\n\u001b[0m\u001b[1;32m    881\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mfrom_proto\u001b[0;34m(context_def, import_scope)\u001b[0m\n\u001b[1;32m   1620\u001b[0m       \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mWhileContext\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m     \"\"\"\n\u001b[0;32m-> 1622\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnested_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested_contexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, maximum_iterations, parallel_iterations, back_prop, swap_memory, name, grad_state, context_def, import_scope)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \"\"\"\n\u001b[1;32m   1430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m       \u001b[0mControlFlowContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_init_from_proto\u001b[0;34m(self, context_def, import_scope)\u001b[0m\n\u001b[1;32m   1519\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtensor_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsLoopEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1522\u001b[0m           \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m           op._set_attr(\"frame_name\",\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/ops/control_flow_util.py\u001b[0m in \u001b[0;36mIsLoopEnter\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIsLoopEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;34m\"\"\"Returns true if `op` is an Enter.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Enter\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RefEnter\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib64/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2254\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#NLP\n",
    "#import spacy\n",
    "import re\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm  # progress bar\n",
    "\n",
    "# file loading\n",
    "import pickle\n",
    "\n",
    "#deep learning\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from time import process_time\n",
    "import resource\n",
    "\n",
    "### try this right after imports to load elmo_in_smalls\n",
    "elmo_in_smalls = np.load('/home/ec2-user/NLP_projects/job_recommender_project/elmo_resumes_under_100_sentences.npy', allow_pickle=True).tolist()\n",
    "elmo_chec = elmo_in_smalls.copy\n",
    "\n",
    "##################reset default graph tf###################\n",
    "tf.reset_default_graph()\n",
    "############################################\n",
    "\n",
    "## this was the instantiation of elmo\n",
    "elmo = hub.Module(\"/home/ec2-user/module/module_elmo2\", trainable=False)\n",
    "\n",
    "# for all embeddings\n",
    "# resume_embeddings_append_regular = []\n",
    "resume_embeddings_append_transpose = []\n",
    "# resume_embeddings_extend_regular = []\n",
    "# resume_embeddings_extend_transpose = []\n",
    "\n",
    "\n",
    "# print('\\n\\nstarting session\\n\\n')\n",
    "t0 = process_time()\n",
    "with tf.Session() as session:\n",
    "    t00 = process_time()\n",
    "#     print('\\nstarting tf.Session took: {}'.format(t00-t0))\n",
    "    \n",
    "    t_pre_initialize_vars = process_time()\n",
    "    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "    t_post_initialize_vars = process_time()\n",
    "#     print('Time to initialize variables: {}'.format(t_post_initialize_vars-t_pre_initialize_vars))\n",
    "\n",
    "    \n",
    "    \n",
    "#     print('\\n\\nstarting for loop\\n\\n')\n",
    "    for i in tqdm(range(250, 355)):\n",
    "        t1 = process_time()\n",
    "        # save np array of embeddings\n",
    "        if i % 50 == 0:\n",
    "            np_ELMo_embeddings_resumes = np.asarray(resume_embeddings_append_transpose)\n",
    "            np.save('ELMo_embeddings_resumes_250_to_{}'.format(i), np_ELMo_embeddings_resumes) \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "#         assign_op = x.assign(1)\n",
    "#         sess.run(assign_op)  # or `assign_op.op.run()`\n",
    "#         print(x.eval())\n",
    "    \n",
    "#         print('elmo_in_smalls[{}]'.format(i))\n",
    "        embeddings_3d = elmo(elmo_in_smalls[i], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "#         print('3d type original', type(embeddings_3d))\n",
    "        t_make_np_start = process_time()\n",
    "        embeddings_3d_np = embeddings_3d.eval()\n",
    "        t_make_np_stop = process_time()          \n",
    "#         print('3d type np?', type(embeddings_3d_np))\n",
    "        \n",
    "        \n",
    "        \n",
    "        embeddings_3d_np_f16 = embeddings_3d_np #tf.dtypes.cast(embeddings_3d_np, tf.float16)\n",
    "#         print('3d size: {}'.format(embeddings_3d_np_f16.shape))\n",
    "#         print('3d type np? 16?', type(embeddings_3d_np_f16))\n",
    "        t2 = process_time()\n",
    "\n",
    "        \n",
    "        embeddings_2d = np.mean(embeddings_3d_np_f16,axis=0)#session.run(tf.reduce_mean(embeddings_3d_np_f16,axis=0))\n",
    "#         print('2d size: {}'.format(embeddings_2d.shape))\n",
    "#         print('2d type ', type(embeddings_2d))\n",
    "        t3 = process_time()\n",
    "\n",
    "\n",
    "        embeddings_1d = np.mean(embeddings_2d,axis=0)#session.run(tf.reduce_mean(tf.convert_to_tensor(embeddings_2d), axis = 0, keepdims=True))\n",
    "#         print('1d size: {}'.format(embeddings_1d.shape))\n",
    "#         print('1d type ', type(embeddings_1d))\n",
    "        t4 = process_time()\n",
    "\n",
    "        transpose = embeddings_1d.T\n",
    "#         print(transpose.shape)\n",
    "#         print('transpose type: ', type(transpose))\n",
    "        t5 = process_time()\n",
    "\n",
    "#         resume_embeddings_append_regular.append(embeddings_1d)\n",
    "        t6 = process_time()\n",
    "\n",
    "        resume_embeddings_append_transpose.append(transpose)\n",
    "        t7 = process_time()\n",
    "\n",
    "#         resume_embeddings_extend_regular.extend(embeddings_1d)\n",
    "        t8 = process_time()\n",
    "\n",
    "#         resume_embeddings_extend_transpose.extend(transpose)\n",
    "        t9 = process_time()\n",
    "\n",
    "#         print('length of resume_embeddings_append_regular: {}'.format(len(resume_embeddings_append_regular)))\n",
    "#         print('length of resume_embeddings_append_transpose: {}'.format(len(resume_embeddings_append_transpose)))\n",
    "#         print('length of resume_embeddings_extend_regular: {}'.format(len(resume_embeddings_extend_regular)))\n",
    "#         print('length of resume_embeddings_extend_transpose: {}'.format(len(resume_embeddings_extend_transpose)))      \n",
    "\n",
    "#         print('shape of resume_embeddings_append_regular[{}]: {}'.format(i, resume_embeddings_append_regular[i].shape))\n",
    "#         print('shape of resume_embeddings_append_transpose[{}]: {}'.format(i, resume_embeddings_append_transpose[i].shape))                                                                        \n",
    "#         print('shape of resume_embeddings_extend_regular[{}]: {}'.format(i, resume_embeddings_extend_regular[i].shape))                                                                        \n",
    "#         print('shape of resume_embeddings_extend_transpose[{}]: {}'.format(i, resume_embeddings_extend_transpose[i].shape))                                                                        \n",
    "\n",
    "        #not .extend?\n",
    "\n",
    "\n",
    "\n",
    "#         print('\\nRun {}'.format(i))\n",
    "        \n",
    "#         print('Iteration ', i, ' maxrss: ', resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "        \n",
    "        print('\\nall times from start of run {}\\n'.format(i))\n",
    "        print('3d embedding time: {}'.format(t_make_np_start - t1))\n",
    "        print('3d tensor to np time: {}'.format(t_make_np_stop - t_make_np_start))\n",
    "        print('3d make 16b time: {}'.format(t2-t_make_np_stop))\n",
    "        print('2d embedding time: {}'.format(t3 - t2))\n",
    "        print('1d embedding time: {}'.format(t4 - t3))\n",
    "        print('time to transpose (t5-t4): {}'.format(t5 - t4))\n",
    "#         print('append_regular time (t6-t5): {}'.format(t6-t5))\n",
    "        print('append_transpose time (t7-t6): {}'.format(t7-t6))\n",
    "#         print('extend_regular time (t8-t7): {}'.format(t8-t7))\n",
    "#         print('extend_transpose time (t9-t8): {}'.format(t9-t8))\n",
    "        print('Total time run {}: {}'.format(i, t9-t1))         \n",
    "        print('\\n\\n\\n\\t\\t\\tEND OF RUN')\n",
    "\n",
    "np_ELMo_embeddings_resumes = np.asarray(resume_embeddings_append_transpose)\n",
    "np.save('ELMo_embeddings_resumes_final', np_ELMo_embeddings_resumes)    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings_append_transpose[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was the instantiation of elmo\n",
    "elmo = hub.Module(\"/home/ec2-user/module/module_elmo2\", trainable=False)\n",
    "\n",
    "\n",
    "# for all embeddings\n",
    "\n",
    "resume_embeddings = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, 1)):#len(elmo_in_smalls))):\n",
    "    # save np array of embeddings\n",
    "    if i % 50 == 0:\n",
    "        np_ELMo_embeddings_resumes = np.asarray(resume_embeddings)\n",
    "        np.save('ELMo_embeddings_resumes_401_to_{}'.format(i), np_ELMo_embeddings_resumes) \n",
    "    \n",
    "    print('elmo_in_smalls[{}]'.format(i))\n",
    "    embeddings_3d = elmo(elmo_in_smalls[i], signature=\"default\",as_dict=True)[\"elmo\"]\n",
    "    print('3d size: {}'.format(embeddings_3d.shape))\n",
    "    print('3d type ', type(embeddings_3d))\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings_2d = session.run(tf.reduce_mean(embeddings_3d,axis=0))\n",
    "        print('2d size: {}'.format(embeddings_2d.shape))\n",
    "        print('2d type ', type(embeddings_2d))\n",
    "        \n",
    "        embeddings_1d = session.run(tf.reduce_mean(tf.convert_to_tensor(embeddings_2d), axis = 0, keepdims=True))\n",
    "        print('1d size: {}'.format(embeddings_1d.shape))\n",
    "        print('1d type ', type(embeddings_1d))\n",
    "        \n",
    "        transpose = embeddings_1d.T\n",
    "        print(transpose.shape)\n",
    "        print('transpose type: ', type(transpose))\n",
    "\n",
    "        resume_embeddings.append(transpose)\n",
    "        \n",
    "        print('length of resume_embeddings: {}'.format(len(resume_embeddings)))\n",
    "        print('shape of resume_embeddings[{}]: {}'.format(i, resume_embeddings[i].shape))\n",
    "        #not .extend?\n",
    "\n",
    "        \n",
    "        #####closing session at everytime\n",
    "        session.close()\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resume_embeddings_append_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings_append_regular[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings_append_transpose[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f32 = 3/1048\n",
    "f32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f16 = np.float16(3/1048)\n",
    "f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(resume_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(resume_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resume_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save np array of embeddings\n",
    "# np_ELMo_embeddings_resumes = np.asarray(resume_embeddings)\n",
    "# np.save('ELMo_embeddings_resumes_401_{}'.format(len(elmo_in_smalls)', np_ELMo_embeddings_resumes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save elmo_train_new\n",
    "# pickle_out = open(\"ELMo_embeddings_resumes.pickle\",\"wb\")\n",
    "# pickle.dump(np_ELMo_embeddings_resumes, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
